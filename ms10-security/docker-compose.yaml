version: '3.1'
services:
  db:
    hostname: mysql
    image: mysql:8.0.23
    restart: always
    volumes:
      - db_data:/var/lib/mysql
    environment:
      MYSQL_ROOT_PASSWORD: password
    ports:
      - 3306:3306
  adminer:
    hostname: mysql
    image: adminer
    restart: always
    ports:
      - 8580:8080
#  kafdrop:
#    image: obsidiandynamics/kafdrop
#    restart: "no"
#    ports:
#      - "9000:9000"
#    environment:
#      KAFKA_BROKERCONNECT: "kafka:32455"
#      JVM_OPTS: "-Xms16M -Xmx48M -Xss180K -XX:-TieredCompilation -XX:+UseStringDeduplication -noverify"
#    depends_on:
#      - "kafka"
#  kafka:
#    image: obsidiandynamics/kafka
#    restart: "no"
#    ports:
#      - "2181:2181"
#      - "9092:9092"
#    environment:
#      KAFKA_LISTENERS: "INTERNAL://:29092,EXTERNAL://:9092"
#      KAFKA_ADVERTISED_LISTENERS: "INTERNAL://kafka:29092,EXTERNAL://localhost:9092"
#      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT"
#      KAFKA_INTER_BROKER_LISTENER_NAME: "INTERNAL"
#      KAFKA_ZOOKEEPER_SESSION_TIMEOUT: "6000"
#      KAFKA_RESTART_ATTEMPTS: "10"
#      KAFKA_RESTART_DELAY: "5"
#      ZOOKEEPER_AUTOPURGE_PURGE_INTERVAL: "0"
#  elasticsearch:
#    image: docker.elastic.co/elasticsearch/elasticsearch:7.8.1
#    environment:
#      - node.name=elasticsearch
#      - cluster.name=es-docker-cluster
#      - discovery.seed_hosts=elasticsearch
#      - cluster.initial_master_nodes=elasticsearch
#      - bootstrap.memory_lock=true
#      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
#    ulimits:
#      memlock:
#        soft: -1
#        hard: -1
#    volumes:
#      - elasticsearch_data:/usr/share/elasticsearch/data
#    ports:
#      - 9200:9200
#  logstash:
#    build:
#      context: logstash/
#      args:
#        ELK_VERSION: 7.8.1
#    volumes:
#      - type: bind
#        source: ./logstash/config/logstash.yml
#        target: /usr/share/logstash/config/logstash.yml
#        read_only: true
#      - type: bind
#        source: ./logstash/pipeline
#        target: /usr/share/logstash/pipeline
#        read_only: true
#    ports:
#      - "5000:5000/tcp"
#      - "5000:5000/udp"
#      - "9600:9600"
#    environment:
#      LS_JAVA_OPTS: "-Xmx256m -Xms256m"
#    depends_on:
#      - elasticsearch
#  apm-server:
#    image: docker.elastic.co/apm/apm-server:7.7.1
#    ports:
#      - 8200:8200
#    environment:
#      - output.elasticsearch.hosts=['http://elasticsearch:9200']
#      - apm-server.host="0.0.0.0:8200"
#      - apm-server.secret_token="xxVpmQB2HMzCL9PgBHVrnxjNXXw5J7bd79DFm6sjBJR5HPXDhcF8MSb3vv4bpg44"
#      - setup.kibana.host="kibana:5601"
#      - setup.template.enabled=true
#      - logging.to_files=false
#    depends_on:
#      - elasticsearch
#      - kibana
#  kibana:
#    image: docker.elastic.co/kibana/kibana:7.8.1
#    ports:
#      - 5601:5601
#    environment:
#      ELASTICSEARCH_URL: http://elasticsearch:9200
#    depends_on:
#      - elasticsearch

volumes:
  db_data:
  elasticsearch_data:

